
```{r setup, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(error = FALSE,echo=FALSE, message=FALSE, warning=FALSE)

rm(list = ls())
project_dir = rstudioapi::getActiveProject();
src_dir = file.path(project_dir, "src/R", fsep="/")
llr_dir = file.path(project_dir, "src/LLR", fsep="/")

data_dir = file.path(project_dir, "data","Exp1_fmri", fsep="/")
result_dir = file.path(project_dir, "results","Exp1_fmri", fsep="/")


source(file.path(src_dir,"envSetup.R",fsep="/"), local = knitr::knit_global())
source(file.path(src_dir,"funcDef.R",fsep="/"), local = knitr::knit_global())
source(file.path(src_dir,"setPlotDefault.R",fsep="/"), local = knitr::knit_global())
```



```{r loadDataset}
fn = file.path(data_dir,"all_participants.csv",fsep="/")
trialdata = read.table(fn, header = TRUE, sep = ",")

data = trialdata%>%filter(ctrl_expt=="True"&ctrl_resp == 1)%>%
  dplyr::select(-c("ctrl_expt","ctrl_resp"))%>%
  group_by(subid,expt_session)%>%
  arrange(expt_block,expt_trial)%>%
  mutate(expt_trial = row_number())

#check if number of trials is correct:
#nsub = length(unique(respdata$subid)) = 29
#ntrialpersub = nrow(respdata)/nsub = 204+27+25*4 = 331
range_xy = c(max(data$stim_x)-min(data$stim_x),
             max(data$stim_y)-min(data$stim_y))
data = data%>%
  mutate(stage = ifelse(training==1,"train","test"))%>%
  mutate(training = factor(training,levels = c(1,0),labels = c("training stimuli","test stimuli")),
         stage = factor(stage,levels = c("train","test")),
         session_str = factor(expt_session, levels = c(1,2,3),labels=c("pretraining","refresher","scanning")),
         stim_xO = stim_x,
         stim_yO = stim_y,
         resp_xO = resp_x,
         resp_yO = resp_y,
         ##rescale so that correct location is between -1 and 1
         stim_x = round(2*stim_x/range_xy[1],digits = 3),
         stim_y = round(2*stim_y/range_xy[2],digits = 3),
         resp_x = round(2*resp_x/range_xy[1],digits = 3),
         resp_y = round(2*resp_y/range_xy[2],digits = 3))%>%
  mutate(resp_dist = sqrt((resp_x-stim_x)^2+(resp_y-stim_y)^2))
```


```{r}
re_Assign_block = data%>%distinct(subid,stage,expt_block,.keep_all = T)%>%
  group_by(subid,stage,expt_session)%>%
  arrange(expt_block)%>%
  mutate(blocknumber_withinsess = row_number(),
         nblocks = n())%>%
  mutate(blocknumws_normalized = blocknumber_withinsess/nblocks)%>%
  dplyr::select(c("subid","stage","expt_block","blocknumber_withinsess","blocknumws_normalized"))
data = left_join(data,re_Assign_block)


```

## Response on screen
### each sub
```{r}
for (pid in unique(data$subid)){
  current_data = filter(data,subid == pid)%>%
    mutate(stim_attrx = factor(stim_attrx),
           stim_attry = factor(stim_attry),
           stim_attryshape = factor(stim_attry,labels = x_shapes))
  nb_train = length(unique(filter(current_data,stage=="train")$expt_block))
  nb_test = length(unique(filter(current_data,stage=="test")$expt_block))
  layoutmat = matrix(c(seq(1,10),
                       seq(11,nb_train), rep(NA,20-nb_train),
                       seq(nb_train+1,nb_train+nb_test)),
                     3, 10, byrow = TRUE)
  (p = current_data%>%
    ggplot(aes(x=resp_x, y = resp_y, color = stim_attrx,fill = stim_attrx))+
    facet_manual(vars(stage,session_str,blocknumber_withinsess),design = layoutmat,strip = strip_nested())+
    #geom_text(aes(label = stim_attryshape))+
    geom_point(aes(shape = stim_attry),size=4)+
    scale_color_manual(values = y_colors,aesthetics = c("color","fill"))+ #RColorBrewer::brewer.pal(5, "Dark2"))+
    scale_shape_manual(values = x_shapes)+
    guides(fill = "none")+
    labs(title = pid,color = "x feature",shape = "y feature", x = "x", y = "y")+
    theme(legend.position = "top"))
  show(p)
  ggsave(file.path(result_dir,'individualmaps',"participant_map_rescaled",paste0(pid,'.png')),plot = p,device = 'png',width = 16,height = 8)
}
```


## Distance  plot all sub in curr dataset
```{r}
data_all = data
data = data_all %>%
   filter(subid %in% paste0('sub',formatC(seq(1,30,1),width = 3,flag = "0")))
```

```{r}
blockdata_sub = aggregate_data(data,
                           yvars = c("resp_dist"),
                           groupbyvars = c("subid","stage","expt_session","blocknumber_withinsess"),
                           stats = c("mu"),
                           additionalvars = c("expt_session","session_str","training"))%>%
  change_cols_name(oldnames = c("mu_resp_dist"),
                   newnames = c("distance"))

blockdata_sum = aggregate_data(blockdata_sub,
                           yvars = c("distance"),
                           groupbyvars = c("expt_session","stage","expt_session","blocknumber_withinsess"),
                           additionalvars = c("session_str","training"),
                           stats = c("mu","se","n"))

(p=ggplot(data = blockdata_sum,
       aes(x=blocknumber_withinsess,y=mu_distance))+
  geom_line()+
  geom_errorbar(aes(ymin = mu_distance - se_distance,
                    ymax = mu_distance + se_distance),
                width=0.4)+
  facet_nested(cols =vars(training,session_str),
               scales = "free_x",space = "free_x")+
  scale_color_manual(values = fourlevel_colors)+
  scale_x_continuous(breaks = seq(0,19,1))+
  labs(x="block number",y="mean distance to goal (a.u.) rescaled",color = "curriculum",
       title = "performance")+
  theme(aspect.ratio = 8,panel.margin = unit(0, "lines")))

ggsave(file.path(result_dir,paste0('rescaled_distance_withsess','.png')),plot = p,device = 'png',width = 12,height = 4)



```
 


## LLR
### load model distribution
```{r}
tryCatch(
  expr = {
    load(file.path(llr_dir,"probDF_data_compo_withlapse.RData"))
  },
  error = function(e){
    print("please generate probability distribution data")
  })
```

### get LLR for each response
```{r}
tryCatch(
  expr = {
    data_with_prob = loadRData(file.path(data_dir,"data_withprob_compo_lapse-0_01.RData"))
  },
  error = function(e){
    cl<- makeCluster(detectCores())
    clusterExport(cl=cl,
                  varlist = c("data","unique_stimloc","base","prob_df_list"),
                  envir=environment())
    new_rows <- pblapply(cl = cl,X = seq(1,nrow(data)),FUN = function(j){
      library(dplyr)
      sx = data$stim_x[j]
      sy = data$stim_y[j]
      rx = data$resp_x[j]
      ry = data$resp_y[j]

      ind = filter(unique_stimloc,x == sx & y == sy)$loc_id
      search_df=prob_df_list[[ind]]
      xlb = base[max(which(base<=rx))]
      xub = base[min(which(base>rx))]
      ylb = base[max(which(base<=ry))]
      yub = base[min(which(base>ry))]
      
      new_row = filter(search_df,x<xub & x>=xlb & y<yub & y>=ylb)
      if(nrow(new_row)==0){
        new_row[1, ] <- NA
        new_row = new_row%>%
        mutate(resp_x = rx, resp_y = ry,
               subid = data$subid[j],
               expt_session = data$expt_sess[j],
               expt_block = data$expt_block[j],
               expt_trial = data$expt_trial[j])
      }else{
        new_row = new_row%>%
        mutate(resp_x = rx, resp_y = ry,
               subid  = data$subid[j],
               expt_session = data$expt_sess[j],
               expt_block = data$expt_block[j],
               expt_trial = data$expt_trial[j])
      }
      
      return(new_row)
      })
    stopCluster(cl)
    
    a = do.call(rbind,new_rows)
    
    data_with_prob = left_join(data,a)
    save(data_with_prob, file = file.path(data_dir,"data_withprob_compo_lapse-0_01.RData"))
  }
)

data_with_prob = loadRData(file.path(data_dir,"data_withprob_compo_lapse-0_01.RData"))

```


### classify learner

```{r}
data_with_prob = data_with_prob%>%
  mutate(error_x = abs(stim_x - resp_x),
         error_y = abs(stim_y - resp_y))%>%
  mutate(binorm_lap = BND_compo_lap)%>%
  mutate(LR_trial = binorm_lap/uniform,
         LRx_trial = UND_x_lap/uniform,
         LRy_trial = UND_y_lap/uniform,)%>%
  mutate(LLR_trial = log(LR_trial),
         LLRx_trial = log(LRx_trial),
         LLRy_trial = log(LRy_trial))%>%
  group_by(subid)%>%
    arrange(stage,expt_session,expt_block)%>%
    mutate(trialid_withinstage = row_number(),
           ntrials = n())%>%
    mutate(trialid_normalized = trialid_withinstage/ntrials)%>%
  ungroup()

sub_LLR_data = aggregate_data(data_with_prob,
                              groupbyvars = c("subid","stage","expt_session","blocknumber_withinsess"),
                              yvars = c("LLR_trial","LLRx_trial","LLRy_trial"),
                              stats = c("mu"),
                              additionalvars = c("expt_coordsys","expt_curricula","expt_session"))%>%
  change_cols_name(oldnames = c("mu_LLR_trial","mu_LLRx_trial","mu_LLRy_trial"),
                   newnames = c("LLR","LLR_x","LLR_y"))

dividesub = sub_LLR_data%>%
  dplyr::select(-c(starts_with("n_")))%>%
  group_by(subid,stage)%>%
  mutate(nblock = max(blocknumber_withinsess))%>%
  aggregate_data(groupbyvars = c("subid","stage","expt_session"),
                 yvars = c("LLR"),
                 stats = c("sum"))

learnerids = unique(filter(dividesub,expt_session==3&stage=="train"&sum_LLR>=0)$subid)
generalizerids = unique(filter(dividesub,expt_session==3&stage=="test"&sum_LLR>=0)$subid)
(nonlearnerids = unique(filter(dividesub,expt_session==3&stage=="train"&sum_LLR<0)$subid))
(nongeneralizerids = unique(filter(dividesub,expt_session==3&stage=="test"&sum_LLR<0)$subid))

data_with_prob = data_with_prob%>%
  mutate(islearner = ifelse(subid%in%learnerids,1,0),
         isgeneralizer = ifelse(subid%in%generalizerids ,1,0))

sub_LLR_data = sub_LLR_data%>%
  mutate(islearner = ifelse(subid%in%learnerids,1,0),
         isgeneralizer = ifelse(subid%in%generalizerids ,1,0))
```

```{r}
substimLLR = aggregate_data(data_with_prob,
                              groupbyvars = c("subid","stage","expt_session","blocknumber_withinsess","stim_id"),
                              yvars = c("LLR_trial","LLRx_trial","LLRy_trial"),
                              stats = c("mu"),
                              additionalvars = c("expt_coordsys","expt_curricula","expt_session"))%>%
  change_cols_name(oldnames = c("mu_LLR_trial","mu_LLRx_trial","mu_LLRy_trial"),
                   newnames = c("LLR","LLR_x","LLR_y"))

substimLLR_mean = data_with_prob%>%
  dplyr::select(-c(starts_with("n_")))%>%
  group_by(subid,stage)%>%
  mutate(nblock = max(blocknumber_withinsess))%>%
  aggregate_data(groupbyvars = c("subid","stage","expt_session","stim_id"),
                 yvars = c("LLR_trial","LLRx_trial","LLRy_trial"),
                 stats = c("mu"))%>%
  change_cols_name(oldnames = c("mu_LLR_trial","mu_LLRx_trial","mu_LLRy_trial"),
                   newnames = c("mu_LLR","mu_LLRx","mu_LLRy"))

write_csv(filter(substimLLR_mean,expt_session==3),
          file.path(data_dir,"scanner_test_LLR.csv"))
```


## Plot learner data
```{r}
blockdata_sub = aggregate_data(data_with_prob,
                           yvars = c("resp_dist","LLR_trial","LLRx_trial","LLRy_trial","error_x","error_y"),
                           groupbyvars = c("subid","stage","expt_session","blocknumber_withinsess"),
                           stats = c("mu"),
                           additionalvars = c("islearner","isgeneralizer","session_str"))%>%
  change_cols_name(oldnames = c("mu_LLR_trial","mu_LLRx_trial","mu_LLRy_trial",
                                "mu_resp_dist","mu_error_x","mu_error_y"),
                   newnames = c("LLR","LLR_x","LLR_y",
                                "distance","errorx","errory"))%>%
  mutate(islearner = factor(islearner,levels = c(0,1),labels = c("non-learner","learner")),
         isgeneralizer = factor(isgeneralizer,levels = c(0,1),labels = c("non-generalizer","generalizer")))


blockdata_sum = aggregate_data(blockdata_sub,
                           yvars = c("distance","LLR","LLR_x","LLR_y","errorx","errory"),
                           groupbyvars = c("islearner","isgeneralizer","stage",
                                           "expt_session","blocknumber_withinsess"),
                           stats = c("mu","se","n"),
                           additionalvars = c("session_str"))
```

```{r}
nlearners = length(learnerids)
ngeneralizers = length(generalizerids)
nsub = length(unique(sub_LLR_data$subid))
participant_count = blockdata_sub%>%
  distinct(subid,islearner,isgeneralizer)%>%
  group_by(islearner,isgeneralizer)%>%
  summarise(n = n())
participant_count = participant_count%>%
  mutate(label = paste0(isgeneralizer, "\n n=",n))
participant_count
labelling_func = function(row){
  l = row[1]
  g = row[2]
  return(filter(participant_count,islearner==l&isgeneralizer==g)$label)
}
```

### plot rescaled distance to goal of learned participants
```{r}
(p = blockdata_sub%>%
  ggplot(aes(x=blocknumber_withinsess,y=distance))+
  geom_point(alpha = 0.3,size = 2,stroke=0)+
  geom_line(data = blockdata_sum,
            aes(x=blocknumber_withinsess,y=mu_distance))+
  geom_errorbar(data = blockdata_sum,
                aes(x=blocknumber_withinsess,
                    y = mu_distance,
                    ymin = mu_distance - se_distance,
                    ymax = mu_distance + se_distance),
                width=0.4)+
  facet_nested(cols =vars(stage,session_str),
               rows = vars(islearner,isgeneralizer),
               scales = "free_x",space = "free_x")+
  scale_x_continuous(breaks = seq(1,12,1))+
  labs(x="block number",y="mean distance to goal (a.u.) rescaled",color = "curriculum",
       title = "performance of learners and generalizers")+
  theme(aspect.ratio = 6,legend.position = "top"))

ggsave(file.path(result_dir,paste0('rescaled_distance_classified','.png')),plot = p,device = 'png',width = 10,height = 9)
```


```{r}
# with data count
blockdata_sub$generalizer_label =
apply(blockdata_sub[ , c("islearner","isgeneralizer")], 1, labelling_func)
blockdata_sum$generalizer_label =
apply(blockdata_sum[ , c("islearner","isgeneralizer")], 1, labelling_func)
(p = blockdata_sub%>%
  ggplot(aes(x=blocknumber_withinsess,y=distance))+
  geom_point(alpha = 0.3,size = 2,stroke=0)+
  geom_line(data = blockdata_sum,
            aes(x=blocknumber_withinsess,y=mu_distance))+
  geom_errorbar(data = blockdata_sum,
                aes(x=blocknumber_withinsess,
                    y = mu_distance,
                    ymin = mu_distance - se_distance,
                    ymax = mu_distance + se_distance),
                width=0.4)+
  facet_nested(cols =vars(stage,session_str),
               rows = vars(islearner,generalizer_label),
               scales = "free_x",space = "free_x")+
  scale_x_continuous(breaks = seq(1,12,1))+
  labs(x="block number",y="mean distance to goal (a.u.) rescaled",color = "curriculum",
       title = "Distance to correct location")+
  theme(aspect.ratio = 5,legend.position = "top"))

ggsave(file.path(result_dir,paste0('rescaled_distance_classified','.png')),plot = p,device = 'png',width = 10.5,height = 7)
```

### plot mean LLR of learned participants
```{r}
(p = blockdata_sub%>%
  ggplot(aes(x=blocknumber_withinsess,y=LLR))+
  geom_point(alpha = 0.2,size = 2,stroke = 0)+
   #geom_line(aes(group = subid),alpha = 0.4,size = 0.2)+
  geom_line(data = blockdata_sum,
            aes(x=blocknumber_withinsess,y=mu_LLR))+
  geom_errorbar(data = blockdata_sum,
                aes(x=blocknumber_withinsess,
                    y = mu_LLR,
                    ymin = mu_LLR - se_LLR,
                    ymax = mu_LLR + se_LLR),
                width=0.4)+
  facet_nested(cols =vars(stage,session_str),
               rows = vars(islearner,isgeneralizer),
               scales = "free_x",space = "free_x")+
  scale_x_continuous(breaks = seq(1,12,1))+
  labs(x="block number",y="mean LLR",color = "curriculum",
       title = "performance of learners and generalizers")+
  theme(aspect.ratio = 6,legend.position = "top"))

ggsave(file.path(result_dir,paste0('LLR_classified','.png')),plot = p,device = 'png',width = 10,height = 9)
```

```{r}
#withdatacount
(p = blockdata_sub%>%
  ggplot(aes(x=blocknumber_withinsess,y=LLR))+
  geom_point(alpha = 0.3,size = 2,stroke=0)+
  geom_line(data = blockdata_sum,
            aes(x=blocknumber_withinsess,y=mu_LLR))+
  geom_errorbar(data = blockdata_sum,
                aes(x=blocknumber_withinsess,
                    y = mu_LLR,
                    ymin = mu_LLR - se_LLR,
                    ymax = mu_LLR + se_LLR),
                width=0.4)+
  facet_nested(cols =vars(stage,session_str),
               rows = vars(islearner,generalizer_label),
               scales = "free_x",space = "free_x")+
  scale_x_continuous(breaks = seq(1,12,1))+
  labs(x="block number",y="mean LLR",color = "curriculum",
       title = "Log-Likelihood Ratio")+
  theme(aspect.ratio = 5,legend.position = "top"))

ggsave(file.path(result_dir,paste0('LLR_classified','.png')),plot = p,device = 'png',width = 10.5,height = 7)
```

### plot individual LLR with map resp

#### 2D only
```{r}
for (pid in unique(filter(data_with_prob)$subid)){
  current_data = filter(data_with_prob,subid == pid)%>%
    mutate(stim_attrx = factor(stim_attrx),
           stim_attry = factor(stim_attry),
           islearner = factor(islearner,levels = c(0,1),labels = c("non-learner","learner")),
           isgeneralizer = factor(isgeneralizer,levels = c(0,1),labels = c("non-generalizer","generalizer")))
  
  psub.title = paste(pid,unique(current_data$islearner),unique(current_data$isgeneralizer))
  nb_train = length(unique(filter(current_data,stage=="train")$expt_block))
  nb_test = length(unique(filter(current_data,stage=="test")$expt_block))
  layoutmat = matrix(c(seq(1,10),
                       seq(11,nb_train), rep(NA,20-nb_train),
                       seq(nb_train+1,nb_train+nb_test)),
                     3, 10, byrow = TRUE)
  (p = current_data%>%
    ggplot(aes(x=resp_x, y = resp_y))+
    facet_manual(vars(stage,session_str,blocknumber_withinsess),design = layoutmat,strip = strip_nested())+
    geom_point(aes(color = stim_attry,fill = stim_attry,shape = stim_attrx),size = 2)+
    geom_text(data = filter(blockdata_sub, subid == pid),
              aes(x=0.1,y=1.8,label = sprintf("LLR = %s", formatC(LLR, digits = 2))))+
    scale_color_manual(values = y_colors,aesthetics = c("color","fill"))+ #RColorBrewer::brewer.pal(5, "Dark2"))+
    scale_shape_manual(values = x_shapes)+
    guides(fill = "none")+
    labs(title = psub.title,
         color = "y feature",shape = "x feature", x = "x", y = "y")+
    theme(legend.position = "top"))
  show(p)
  ggsave(file.path(result_dir,'individualmaps',"participant_map_withLLR",paste0(pid,'.png')),plot = p,device = 'png',width = 16,height = 8)
}
```

#### 2D + 1D
```{r}
for (pid in unique(filter(data_with_prob)$subid)){
  current_data = filter(data_with_prob,subid == pid)%>%
    mutate(stim_attrx = factor(stim_attrx),
           stim_attry = factor(stim_attry),
           islearner = factor(islearner,levels = c(0,1),labels = c("non-learner","learner")),
           isgeneralizer = factor(isgeneralizer,levels = c(0,1),labels = c("non-generalizer","generalizer")))
  
  psub.title = paste(pid,unique(current_data$islearner),unique(current_data$isgeneralizer))
  nb_train = length(unique(filter(current_data,stage=="train")$expt_block))
  nb_test = length(unique(filter(current_data,stage=="test")$expt_block))
  layoutmat = matrix(c(seq(1,10),
                       seq(11,nb_train), rep(NA,20-nb_train),
                       seq(nb_train+1,nb_train+nb_test)),
                     3, 10, byrow = TRUE)
  (p = current_data%>%
    ggplot(aes(x=resp_x, y = resp_y))+
    facet_manual(vars(stage,session_str,blocknumber_withinsess),design = layoutmat,strip = strip_nested())+
    geom_point(aes(color = stim_attry,fill = stim_attry,shape = stim_attrx),size = 3)+
    geom_text(data = filter(blockdata_sub, subid == pid),size = 3,
              aes(x=0.1,y=2,label = sprintf("2D LLR = %s", formatC(LLR, digits = 2))))+
    geom_text(data = filter(blockdata_sub, subid == pid),size = 3,
              aes(x=0.1,y=1.6,
                  label = sprintf("1D LLR(x,y): [%s, %s]",
                                  formatC(LLR_x, digits = 2),
                                  formatC(LLR_y, digits = 2))))+
    scale_color_manual(values = y_colors,aesthetics = c("color","fill"))+
    scale_shape_manual(values = x_shapes)+
    guides(fill = "none")+
    labs(title = psub.title,
         color = "x feature",shape = "y feature", x = "x", y = "y")+
    theme(legend.position = "top"))
  ggsave(file.path(result_dir,'individualmaps',"participant_map_with1dLLR",paste0(pid,'.png')),plot = p,width = 16,height = 9)
  
}
```

### average response map
```{r}
generalize_js = c("non-generalizer","generalizer")
learn_ks = c("non-learner","learner")
for (j in c(0,1)){
  for (k in c(0,1)){
    ave_resp_map_df = data_with_prob %>%
    filter(isgeneralizer==j,islearner==k)%>%
    aggregate_data(
      yvars = c("resp_x","resp_y"),
      groupbyvars = c("islearner","isgeneralizer","stage","expt_session","blocknumber_withinsess","stim_id"),
      stats = c("mu"),
      additionalvars = c("expt_block","session_str","stim_x","stim_y","stim_attrx","stim_attry")
    )%>%
    change_cols_name(oldnames = c("mu_resp_x","mu_resp_y"),
                     newnames = c("resp_x", "resp_y"))%>%
    mutate(stim_attrx = factor(stim_attrx),
             stim_attry = factor(stim_attry))
  
  
  nb_train = length(unique(filter(ave_resp_map_df,stage=="train")$expt_block))
  nb_test = length(unique(filter(ave_resp_map_df,stage=="test")$expt_block))
  layoutmat = matrix(c(seq(1,10),
                       seq(11,nb_train), rep(NA,20-nb_train),
                       seq(nb_train+1,nb_train+nb_test)),
                     3, 10, byrow = TRUE)
  (p = ave_resp_map_df%>%
    ggplot(aes(x=resp_x, y = resp_y))+
    facet_manual(vars(stage,session_str,blocknumber_withinsess),design = layoutmat,strip = strip_nested())+
    geom_point(aes(color = stim_attry,fill = stim_attry,shape = stim_attrx),size = 3)+
    scale_color_manual(values = y_colors,aesthetics = c("color","fill"))+
    scale_shape_manual(values = x_shapes)+
    guides(fill = "none")+
    labs(title =paste0("average response map: ", learn_ks[k+1],'_',generalize_js[j+1]),
      color = "y feature",shape = "x feature", x = "x", y = "y")+
    theme(legend.position = "top"))
  ggsave(file.path(result_dir,'individualmaps',"averagemaps",
                   paste0(learn_ks[k+1],'_',generalize_js[j+1],'.png')),plot = p,width = 16,height = 9)
  }
}

```


### response stability
use correlation/ standard deviation of responses to quantify response stability
1) correlation approach - for each two blocks how correlated are the response?
2) std approach - within several blocks, the standard deviation of responses

#### running average approach
```{r}
stability_df = data.frame()
subid_list = unique(data$subid)
for (pid in subid_list){
  #pid = subid_list[1]
  current_data = data%>%filter(subid==pid)
  unique_train_blocknum = unique(filter(current_data,stage=="train")$expt_block)
  unique_test_blocknum = unique(filter(current_data,stage=="test")$expt_block)
  nb_train = length(unique_train_blocknum)
  nb_test = length(unique_test_blocknum)
  
  stability_trainx = c()
  stability_trainy = c()
  for (i in seq(2,nb_train,1)){
    j=unique_train_blocknum[i-1]
    k=unique_train_blocknum[i]
    prev_x = arrange(filter(current_data,stage=="train",expt_block==j),stim_id)$resp_x
    prev_y = arrange(filter(current_data,stage=="train",expt_block==j),stim_id)$resp_y
    curr_x = arrange(filter(current_data,stage=="train",expt_block==k),stim_id)$resp_x
    curr_y = arrange(filter(current_data,stage=="train",expt_block==k),stim_id)$resp_y
    
    stability_trainx = append(stability_trainx,cor(prev_x,curr_x))
    stability_trainy = append(stability_trainy,cor(prev_y,curr_y))
  }
  train_stabdf = data.frame(stability_x = stability_trainx,
             stability_y=stability_trainy,
             expt_block=unique_train_blocknum[2:nb_train])%>%
    mutate(stage="train",subid=pid)
  
  stability_testx = c()
  stability_testy = c()
  for (i in seq(2,nb_test,1)){
    j=unique_test_blocknum[i-1]
    k=unique_test_blocknum[i]
    prev_x = arrange(filter(current_data,stage=="test",expt_block==j),stim_id)$resp_x
    prev_y = arrange(filter(current_data,stage=="test",expt_block==j),stim_id)$resp_y
    curr_x = arrange(filter(current_data,stage=="test",expt_block==k),stim_id)$resp_x
    curr_y = arrange(filter(current_data,stage=="test",expt_block==k),stim_id)$resp_y
    
    stability_testx = append(stability_testx,
                             cor(prev_x, curr_x))
    stability_testy = append(stability_testy,
                             cor(prev_y, curr_y))
  }
  test_stabdf = data.frame(stability_x = stability_testx,
             stability_y=stability_testy,
             expt_block=unique_test_blocknum[2:nb_test])%>%
    mutate(stage="test",subid=pid)
  
  substab_df = left_join(filter(re_Assign_block,subid==pid,expt_block!=unique_train_blocknum[1],expt_block!=unique_test_blocknum[1]),
                         rbind(train_stabdf,test_stabdf),
                         by = c("subid", "stage", "expt_block"))
  stability_df = rbind(stability_df,substab_df)
}

```


```{r}
stability_df = stability_df %>%
  mutate(islearner = ifelse(subid%in%learnerids,1,0),
         isgeneralizer = ifelse(subid%in%generalizerids ,1,0),
         session_str=factor(expt_session, levels = c(1,2,3),labels=c("pretraining","refresher","scanning")))
stability_df_long =stability_df%>%
  pivot_longer(cols=c("stability_x","stability_y"),names_to = "axis",values_to = "stability")

stability_df_long_sum = stability_df_long%>%
  aggregate_data(yvars = c("stability"),
                 groupbyvars = c("islearner","isgeneralizer","stage",
                                 "expt_session","blocknumber_withinsess","axis"),
                 stats = c("mu","se","n"),
                 additionalvars = c("session_str"))
(p = stability_df_long%>%
    #mutate(blocknumber_withinsess=factor(blocknumber_withinsess))%>%
  ggplot(aes(x=blocknumber_withinsess,y=stability,color=axis))+
  geom_point(alpha = 0.2,size = 2,stroke = 0,position=position_dodge(width=1))+
  #geom_boxplot(position=position_dodge(width=1))+
  geom_line(data = stability_df_long_sum,
            aes(x=blocknumber_withinsess,y=mu_stability),position=position_dodge(width=1))+
  geom_errorbar(data = stability_df_long_sum,
                aes(x=blocknumber_withinsess,
                    y = mu_stability,
                    ymin = mu_stability - se_stability,
                    ymax = mu_stability + se_stability),
                width=0.4,position=position_dodge(width=1))+
  facet_nested(cols =vars(stage,session_str),
               rows = vars(islearner,isgeneralizer),
               scales = "free_x",space = "free_x")+
  scale_x_continuous(breaks = seq(1,12,1))+
  labs(x="block number",y="mean stability",color = "axis",
       title = "performance of learners and generalizers")+
  theme(aspect.ratio = 6,legend.position = "top"))

ggsave(file.path(result_dir,paste0('stability','.png')),plot = p,device = 'png',width = 10,height = 9)
```



## compute correlation with groundtruth map using CCA
```{r}
cca_df = data_with_prob%>%distinct(subid,stage,session_str,blocknumber_withinsess)

cl<- makeCluster(detectCores())
clusterExport(cl=cl,
              varlist = c("cca_df","data_with_prob"),
              envir=environment())
cc_res <- pblapply(cl = cl,X = seq(1,nrow(cca_df)),FUN = function(j){
  config = cca_df[j,]
  current_data = dplyr::left_join(cca_df[j,],data_with_prob)
  groundtruth = dplyr::select(current_data,c("stim_x","stim_y"))
  participant = dplyr::select(current_data,c("resp_x","resp_y"))
  cc <- cancor(groundtruth, participant)
  return(cc)
})
stopCluster(cl)

cca_df = cbind(cca_df,
      do.call(rbind,lapply(cc_res,FUN = function(cc){
                            df = data.frame(t(cc$cor))
                            colnames(df) = c("corrcoef1","corrcoef2")
                            return(df)
                          })
        )
      )
head(cca_df)
```


```{r}
for (pid in unique(filter(data_with_prob)$subid)){
  current_data = filter(data_with_prob,subid == pid)%>%
    mutate(stim_attrx = factor(stim_attrx),
           stim_attry = factor(stim_attry),
           islearner = factor(islearner,levels = c(0,1),labels = c("non-learner","learner")),
           isgeneralizer = factor(isgeneralizer,levels = c(0,1),labels = c("non-generalizer","generalizer")))
  
  psub.title = paste(pid,unique(current_data$islearner),unique(current_data$isgeneralizer))
  nb_train = length(unique(filter(current_data,stage=="train")$expt_block))
  nb_test = length(unique(filter(current_data,stage=="test")$expt_block))
  layoutmat = matrix(c(seq(1,10),
                       seq(11,nb_train), rep(NA,20-nb_train),
                       seq(nb_train+1,nb_train+nb_test)),
                     3, 10, byrow = TRUE)
  (p = current_data%>%
    ggplot(aes(x=resp_x, y = resp_y))+
    facet_manual(vars(stage,session_str,blocknumber_withinsess),design = layoutmat,strip = strip_nested())+
    geom_point(aes(color = stim_attrx,fill = stim_attrx,shape = stim_attry),size = 3)+
    geom_text(data = filter(blockdata_sub, subid == pid),size = 3,
              aes(x=0.1,y=1.6,label = sprintf("LLR = %s", formatC(LLR, digits = 2))))+
    geom_text(data = filter(cca_df, subid == pid),size = 3,
              aes(x=0.1,y=2,
                  label = sprintf("CCA: [%s, %s]",
                                  formatC(corrcoef1, digits = 2),
                                  formatC(corrcoef2, digits = 2))))+
    scale_color_manual(values = y_colors,aesthetics = c("color","fill"))+ #RColorBrewer::brewer.pal(5, "Dark2"))+
    scale_shape_manual(values = x_shapes)+
    guides(fill = "none")+
    labs(title = psub.title,
         color = "x feature",shape = "y feature", x = "x", y = "y")+
    theme(legend.position = "top"))
  ggsave(file.path(result_dir,'individualmaps',"participant_map_withLLRCCA",paste0(pid,'.png')),plot = p,width = 16,height = 9)
  
}
```

## compute correlation with groundtruth map using regression

```{r}
reg_df = data_with_prob%>%distinct(subid,stage,session_str,blocknumber_withinsess)

cl<- makeCluster(detectCores())
clusterExport(cl=cl,
              varlist = c("reg_df","data_with_prob","change_cols_name"),
              envir=environment())
reg_res <- pblapply(cl = cl,X = seq(1,nrow(reg_df)),FUN = function(j){
  library(dplyr)
  config = reg_df[j,]
  current_data = dplyr::left_join(reg_df[j,],data_with_prob)%>%
    mutate(resp_x = scale(resp_x),
           resp_y = scale(resp_y),
           stim_x = scale(stim_x),
           stim_y = scale(stim_y))
  resx = lm(resp_x~stim_x,current_data)
  resy = lm(resp_y~stim_y,current_data)
  sumx = summary(resx)
  sumy = summary(resy)
  
  df_x = data.frame(t(sumx[["fstatistic"]]))%>%
    mutate(p = pf(sumx$fstatistic[1],sumx$fstatistic[2],sumx$fstatistic[3],lower.tail=FALSE))%>%
    change_cols_name(oldnames = colnames(.),newnames = c("Fvalue_x","Fnumdf_x","Fdendf_x","Fpvalue_x"))%>%
    mutate(coef_x = resx[["coefficients"]][["stim_x"]])
  
  df_y = data.frame(t(sumy[["fstatistic"]]))%>%
    mutate(p = pf(sumy$fstatistic[1],sumy$fstatistic[2],sumy$fstatistic[3],lower.tail=FALSE))%>%
    change_cols_name(oldnames = colnames(.),newnames = c("Fvalue_y","Fnumdf_y","Fdendf_y","Fpvalue_y"))%>%
    mutate(coef_y = resy[["coefficients"]][["stim_y"]])

  df <- cbind(df_x,df_y)
  return(df)
})
stopCluster(cl)

reg_df = data_with_prob%>%distinct(subid,stage,session_str,blocknumber_withinsess)
reg_df = cbind(reg_df,
               do.call(rbind,reg_res))%>%
  mutate(sigif_1Dx = case_when(Fpvalue_x>=0.05~sprintf("%.2f%s",coef_x,""),
                               Fpvalue_x>=0.01 & Fpvalue_x<0.05~sprintf("%.2f%s",coef_x,"*"),
                               Fpvalue_x>=0.001 & Fpvalue_x<0.01~sprintf("%.2f%s",coef_x,"**"),
                               Fpvalue_x<0.001~sprintf("%.2f%s",coef_x,"***")),
         
         sigif_1Dy = case_when(Fpvalue_y>=0.05~sprintf("%.2f%s",coef_y,""),
                               Fpvalue_y>=0.01 & Fpvalue_y<0.05~sprintf("%.2f%s",coef_y,"*"),
                               Fpvalue_y>=0.001 & Fpvalue_y<0.01~sprintf("%.2f%s",coef_y,"**"),
                               Fpvalue_y<0.001~sprintf("%.2f%s",coef_y,"***")))%>%
  mutate(textcoef1D = paste0("\u03b2x = ",sigif_1Dx,", \u03b2y = ",sigif_1Dy)
        )
head(reg_df)
```

```{r}
for (pid in unique(filter(data_with_prob)$subid)){
  current_data = filter(data_with_prob,subid == pid)%>%
    mutate(stim_attrx = factor(stim_attrx),
           stim_attry = factor(stim_attry),
           islearner = factor(islearner,levels = c(0,1),labels = c("non-learner","learner")),
           isgeneralizer = factor(isgeneralizer,levels = c(0,1),labels = c("non-generalizer","generalizer")))
  
  psub.title = paste(pid,unique(current_data$islearner),unique(current_data$isgeneralizer))
  nb_train = length(unique(filter(current_data,stage=="train")$expt_block))
  nb_test = length(unique(filter(current_data,stage=="test")$expt_block))
  layoutmat = matrix(c(seq(1,10),
                       seq(11,nb_train), rep(NA,20-nb_train),
                       seq(nb_train+1,nb_train+nb_test)),
                     3, 10, byrow = TRUE)
  (p = current_data%>%
    ggplot(aes(x=resp_x, y = resp_y))+
    facet_manual(vars(stage,session_str,blocknumber_withinsess),design = layoutmat,strip = strip_nested())+
    geom_point(aes(color = stim_attrx,fill = stim_attrx,shape = stim_attry),size = 3)+
    geom_text(data = filter(blockdata_sub, subid == pid),size = 3,
              aes(x=0.1,y=2.1,label = sprintf("LLR = %s", formatC(LLR, digits = 2))))+
    geom_text(data = filter(blockdata_sub, subid == pid),size = 2.5,
              aes(x=0.1,y=1.85,
                  label = sprintf("1D LLR(x,y): [%s, %s]",
                                  formatC(LLR_x, digits = 2),
                                  formatC(LLR_y, digits = 2))))+
    geom_text(data = filter(reg_df, subid == pid),size = 2.5,
                  fill = NA, label.color = NA,label.padding = grid::unit(rep(0, 4), "pt"),
                  aes(x=0,y=1.6,label = textcoef1D))+
    scale_color_manual(values = y_colors,aesthetics = c("color","fill"))+
    scale_shape_manual(values = x_shapes)+
    guides(fill = "none")+
    labs(title = psub.title,
         color = "x feature",shape = "y feature", x = "x", y = "y")+
    theme(legend.position = "top"))
  ggsave(file.path(result_dir,'individualmaps',"participant_map_with1dcoef",paste0(pid,'.png')),plot = p,width = 16,height = 9)
  
}
```



# Error Analysis
```{r}
data_with_prob =
  data_with_prob%>%
  mutate(resp_samexsign = sign(resp_x) == sign(stim_x),
         resp_sameysign = sign(resp_y) == sign(stim_y)
         )%>%
  mutate(resp_samequad = resp_samexsign & resp_sameysign)
err_blocksum = data_with_prob%>%
  filter(abs(stim_x)==0.5, abs(stim_y)==0.5)%>%
  aggregate_data(
    yvars = c("resp_samexsign","resp_sameysign","resp_samequad"),
    groupbyvars = c("subid","stage","expt_session","blocknumber_withinsess"),
    stats = c("mu"),
    additionalvars = c("islearner","isgeneralizer","session_str")
  )%>%
  change_cols_name(oldnames = c("mu_resp_samexsign","mu_resp_sameysign","mu_resp_samequad"),
                   newnames = c("resp_samexsign","resp_sameysign","resp_samequad"))%>%
  mutate(islearner = factor(islearner,levels = c(0,1),labels = c("non-learner","learner")),
         isgeneralizer = factor(isgeneralizer,levels = c(0,1),labels = c("non-generalizer","generalizer")))
err_groupsum = err_blocksum %>%
  aggregate_data(
    yvars = c("resp_samexsign","resp_sameysign","resp_samequad"),
    groupbyvars = c("stage","expt_session","blocknumber_withinsess","islearner","isgeneralizer"),
    stats = c("mu","se"),
    additionalvars = c("session_str")
  )
```

```{r}
p_err = err_blocksum %>%
  ggplot(aes(x=blocknumber_withinsess,y=resp_samequad))+
  geom_point(alpha = 0.3,size = 2,stroke=0)+
  geom_line(data = err_groupsum,
            aes(x=blocknumber_withinsess,y=mu_resp_samequad))+
  geom_errorbar(data = err_groupsum,
                aes(x=blocknumber_withinsess,
                    y = mu_resp_samequad,
                    ymin = mu_resp_samequad - se_resp_samequad,
                    ymax = mu_resp_samequad + se_resp_samequad),
                width=0.4)+
  facet_nested(cols =vars(stage,session_str),
               rows = vars(islearner,isgeneralizer),
               scales = "free_x",space = "free_x")+
  scale_x_continuous(breaks = seq(1,6,1))+
  labs(x="block number",y="percentage of error in the same quadrant",color = "curriculum",
       title = "performance of learners and generalizers")+
  theme(aspect.ratio = 2,legend.position = "top")
ggsave(file.path(result_dir,paste0('errors','.png')),plot = p_err,device = 'png',width = 10,height = 9)
```

# Correlation of behavior with different model RDM throughout training

```{r}
keepcols = c("subid","stage","session_str","blocknumber_withinsess",
             "islearner","isgeneralizer")
reg_df = data_with_prob%>%distinct(subid,stage,session_str,blocknumber_withinsess,.keep_all = TRUE)%>%
  dplyr::select(all_of(keepcols))

cl<- makeCluster(detectCores())
clusterExport(cl=cl,
              varlist = c("reg_df","data_with_prob","change_cols_name"),
              envir=environment())
reg_res <- pblapply(cl = cl,X = seq(1,nrow(reg_df)),FUN = function(j){
  library(dplyr)
  config = reg_df[j,]
  curr_df = dplyr::left_join(config,data_with_prob)%>%
              arrange(stim_id)
  resp_loc = cbind(curr_df[["resp_x"]],curr_df[["resp_y"]])
  attrx_onehot = model.matrix(~factor(stim_attrx)-1,curr_df)
  attry_onehot = model.matrix(~factor(stim_attry)-1,curr_df)
  theo_loc = list(
    stim_x = curr_df[["stim_x"]],
    stim_y = curr_df[["stim_y"]],
    feature_x = attrx_onehot,
    feature_y = attry_onehot,
    global_x = sign(curr_df[["stim_x"]]),
    global_y = sign(curr_df[["stim_y"]]),
    local_x = abs(curr_df[["stim_x"]]),
    local_y = abs(curr_df[["stim_y"]]),
    cartesian_2D = cbind(curr_df[["stim_x"]],curr_df[["stim_y"]]),
    feature_2D = cbind(attrx_onehot,attry_onehot),
    hierarchical_global = sign(cbind(curr_df[["stim_x"]],curr_df[["stim_y"]])),
    hierarchical_local = abs(cbind(curr_df[["stim_x"]],curr_df[["stim_y"]]))
  )
  
  theo_rdm = list()
  rdms = list()
  for (theo_name in names(theo_loc)){
    theo_rdm[[theo_name]] = dist(theo_loc[[theo_name]], method = "euclidean")
    rdms[[theo_name]] = scale(c(theo_rdm[[theo_name]]), scale = TRUE)
  }
  resp_rdm = dist(resp_loc, method = "euclidean")
  #heatmap(as.matrix(resp_rdm),Rowv = NA, Colv = NA)
  rdms[["response"]] = c(resp_rdm)
  rdm_df = data.frame(rdms)
  rdm_reg = lm(response~cartesian_2D+feature_2D+hierarchical_global+hierarchical_local,rdm_df)
  #rdm_reg = lm(response~stim_x+stim_y+feature_x+feature_y+
  #               global_x+global_y+local_x+local_y,rdm_df)
  reg_res_df = data.frame(rdm_reg$coefficients)
  reg_res_df["coefficient"] = row.names(reg_res_df)
  row.names(reg_res_df) = NULL
  
  df = cbind(reg_res_df, reg_df[j,][rep(1,nrow(reg_res_df)),])
  return(df)
})
stopCluster(cl)
```




```{r}
reg_rdm_df = do.call(rbind,reg_res)%>%
  change_cols_name(oldnames = c("rdm_reg.coefficients","coefficient"),
                   newnames = c("coef","modelrdm"))%>%
  mutate(islearner = factor(islearner,levels = c(0,1),labels = c("non-learner","learner")),
         isgeneralizer = factor(isgeneralizer,levels = c(0,1),labels = c("non-generalizer","generalizer")))%>%
  filter(modelrdm!="(Intercept)")

colnames(reg_rdm_df)
reg_rdm_df_agg = 
  aggregate_data(reg_rdm_df,
     yvars= c("coef"),
     groupbyvars = c("islearner","isgeneralizer","stage",
                     "blocknumber_withinsess","modelrdm"),
     stats = c("mu","se","n"),
     additionalvars = c("session_str")
  )

ggplot(data=reg_rdm_df_agg,aes(x=blocknumber_withinsess,color=modelrdm))+
  facet_nested(cols =vars(stage,session_str),
               rows = vars(islearner,isgeneralizer),
               scales = "free_x",space = "free_x")+
  geom_line(aes(y=mu_coef))+
  geom_errorbar(aes(ymin = mu_coef - se_coef,
                    ymax = mu_coef + se_coef),
                width=0.4)+
  scale_x_continuous(breaks = seq(1,12,1))+
  labs(x="block number",y="mean coef",color = "modelrdm",
       title = "performance of learners and generalizers")+
  theme(aspect.ratio = 3,legend.position = "top")
```




```{r}
keepcols = c("subid","stage","session_str","blocknumber_withinsess",
             "islearner","isgeneralizer")
reg_df = data_with_prob%>%distinct(subid,stage,session_str,blocknumber_withinsess,.keep_all = TRUE)%>%
  dplyr::select(all_of(keepcols))

cl<- makeCluster(detectCores())
clusterExport(cl=cl,
              varlist = c("reg_df","data_with_prob","change_cols_name"),
              envir=environment())
reg_res <- pblapply(cl = cl,X = seq(1,nrow(reg_df)),FUN = function(j){
  library(dplyr)
  
  library(tidyr)
  config = reg_df[j,]
  curr_df = dplyr::left_join(config,data_with_prob)%>%
              arrange(stim_id)
  resp_loc = cbind(curr_df[["resp_x"]],curr_df[["resp_y"]])
  attrx_onehot = model.matrix(~factor(stim_attrx)-1,curr_df)
  attry_onehot = model.matrix(~factor(stim_attry)-1,curr_df)
  theo_loc = list(
    stim_x = curr_df[["stim_x"]],
    stim_y = curr_df[["stim_y"]],
    feature_x = attrx_onehot,
    feature_y = attry_onehot,
    global_x = sign(curr_df[["stim_x"]]),
    global_y = sign(curr_df[["stim_y"]]),
    local_x = abs(curr_df[["stim_x"]]),
    local_y = abs(curr_df[["stim_y"]]),
    cartesian_2D = cbind(curr_df[["stim_x"]],curr_df[["stim_y"]]),
    feature_2D = cbind(attrx_onehot,attry_onehot),
    hierarchical_global = sign(cbind(curr_df[["stim_x"]],curr_df[["stim_y"]])),
    hierarchical_local = abs(cbind(curr_df[["stim_x"]],curr_df[["stim_y"]]))
  )
  
  theo_rdm = list()
  rdms = list()
  for (theo_name in names(theo_loc)){
    theo_rdm[[theo_name]] = dist(theo_loc[[theo_name]], method = "euclidean")
    rdms[[theo_name]] = scale(c(theo_rdm[[theo_name]]), scale = TRUE)
  }
  resp_rdm = dist(resp_loc, method = "euclidean")
  #heatmap(as.matrix(resp_rdm),Rowv = NA, Colv = NA)
  rdms[["response"]] = c(resp_rdm)
  rdm_df = data.frame(rdms)
  reg_models = list(
    cartesian_2D_combine = lm(response~cartesian_2D,rdm_df),
    feature_10D_combine = lm(response~feature_2D,rdm_df),
    hierarchical_4D_combine = lm(response~hierarchical_global+hierarchical_local,rdm_df),
    cartesian_2D_separate = lm(response~stim_x+stim_y,rdm_df),
    feature_10D_separate = lm(response~feature_x+feature_y,rdm_df),
    hierarchical_4D_separate = lm(response~global_x+global_y+local_x+local_y,rdm_df)
  )
  rs  = list()
  ars = list()
  aic = list()
  bic = list()
  for (theo_name in names(reg_models)){
    rs[[theo_name]] = summary(reg_models[[theo_name]])[["r.squared"]]
    ars[[theo_name]] = summary(reg_models[[theo_name]])[["adj.r.squared"]]
    aic[[theo_name]] = AIC(reg_models[[theo_name]])
    bic[[theo_name]] = BIC(reg_models[[theo_name]])
  }

  rsquardf = left_join(
    pivot_longer(data.frame(rs),cols = names(reg_models),names_to ="modelrdm",values_to = "Rsquare"),
    pivot_longer(data.frame(ars),cols = names(reg_models),names_to ="modelrdm",values_to = "adjustedRsquare")
  )
  
  icdf = left_join(
    pivot_longer(data.frame(aic),cols = names(reg_models),names_to ="modelrdm",values_to = "AIC"),
    pivot_longer(data.frame(bic),cols = names(reg_models),names_to ="modelrdm",values_to = "BIC")
  )
  
  reg_res_df = left_join(rsquardf,icdf)

  df = cbind(reg_res_df, reg_df[j,][rep(1,nrow(reg_res_df)),])
  return(df)
})
stopCluster(cl)
```



```{r}
reg_rdm_df = do.call(rbind,reg_res)%>%
  mutate(islearner = factor(islearner,levels = c(0,1),labels = c("non-learner","learner")),
         isgeneralizer = factor(isgeneralizer,levels = c(0,1),labels = c("non-generalizer","generalizer")))

colnames(reg_rdm_df)
reg_rdm_df_agg = 
  aggregate_data(reg_rdm_df,
     yvars= c("Rsquare","adjustedRsquare","AIC","BIC"),
     groupbyvars = c("islearner","isgeneralizer","stage",
                     "blocknumber_withinsess","modelrdm"),
     stats = c("mu","se","n"),
     additionalvars = c("session_str")
  )

reg_rdm_df%>%
  #filter(islearner=="learner",isgeneralizer=="generalizer")%>%
  filter(!grepl("separate",modelrdm))%>%
ggplot(data=,
       aes(x=blocknumber_withinsess,color=modelrdm,group=subid))+
  facet_nested(cols =vars(stage,session_str),
               rows = vars(islearner,isgeneralizer),
               scales = "free_x",space = "free_x")+
  geom_point(aes(y=adjustedRsquare,
                color=modelrdm),alpha=.3,position=position_dodge(width=1))+
  #geom_errorbar(aes(ymin = mu_adjustedRsquare - se_adjustedRsquare,
            #        ymax = mu_adjustedRsquare + se_adjustedRsquare),
            #    width=0.4)+
  scale_x_continuous(breaks = seq(1,12,1))+
  labs(x="block number",y="mean adjustedRsquare",color = "model rdm",
       title = "performance of learners and generalizers")+
  theme(aspect.ratio = 6,legend.position = "top")
```



```{r}
reg_rdm_subset = reg_rdm_df%>%
  filter(grepl("separate",modelrdm))
reg_rdm_wide=
reg_rdm_subset%>%
  pivot_wider(id_cols=c(subid,islearner,isgeneralizer,
                        stage,session_str,blocknumber_withinsess),
              values_from = c(AIC,BIC,adjustedRsquare,Rsquare),
              names_from = modelrdm)
mfit_cols = list(
  AIC = lapply(unique(reg_rdm_subset["modelrdm"]),function(x) {paste("AIC",x,sep="_")})$modelrdm,
  BIC = lapply(unique(reg_rdm_subset["modelrdm"]),function(x) {paste("BIC",x,sep="_")})$modelrdm,
  Rsquare = lapply(unique(reg_rdm_subset["modelrdm"]),function(x) {paste("Rsquare",x,sep="_")})$modelrdm,
  adjustedRsquare = lapply(unique(reg_rdm_subset["modelrdm"]),function(x) {paste("adjustedRsquare",x,sep="_")})$modelrdm
)
reg_rdm_wide=reg_rdm_wide%>%
  mutate(
    winning_AIC = substring(
      mfit_cols$AIC[max.col(-reg_rdm_wide[,mfit_cols$AIC],"first")],5),
    winning_BIC = substring(
      mfit_cols$BIC[max.col(-reg_rdm_wide[,mfit_cols$BIC],"first")],5),
    winning_Rsquare = substring(
      mfit_cols$Rsquare[max.col(reg_rdm_wide[,mfit_cols$Rsquare],"first")],9),
    winning_adjustedRsquare = substring(
      mfit_cols$adjustedRsquare[max.col(reg_rdm_wide[,mfit_cols$adjustedRsquare],"first")],17),)
reg_rdm_winning = reg_rdm_wide%>%
  dplyr::select(-c(starts_with("AIC"),starts_with("BIC"),
                   starts_with("adjustedRsquare"),starts_with("Rsquare")))%>%
  pivot_longer(cols = c(winning_AIC,winning_BIC,winning_Rsquare,winning_adjustedRsquare),
               names_to ="criteria",values_to = "modelrdm")

reg_rdm_winning_agg = 
  aggregate_data(reg_rdm_winning,
     yvars= c("subid"),
     groupbyvars = c("islearner","isgeneralizer","stage","session_str","criteria",
                     "blocknumber_withinsess","modelrdm"),
     stats = c("n")
  )%>%
  change_cols_name(oldnames="n_subid",newnames = "n_sub")

reg_rdm_winning_agg%>%
  #filter(islearner=="learner",isgeneralizer=="generalizer")%>%#
  filter(criteria=="winning_adjustedRsquare")%>%
  ggplot(aes(x=blocknumber_withinsess,y=n_sub,fill=modelrdm))+
  facet_nested(cols =vars(stage,session_str),
               rows = vars(islearner,isgeneralizer),
               scales = "free",space = "free_x")+
  geom_col(position="stack")+
  scale_x_continuous(breaks = seq(1,12,1))+
  labs(x="block number",y="number of participants",color = "model rdm",
       title = "winning model rdm")+
  theme(aspect.ratio = 6,legend.position = "top")
```

